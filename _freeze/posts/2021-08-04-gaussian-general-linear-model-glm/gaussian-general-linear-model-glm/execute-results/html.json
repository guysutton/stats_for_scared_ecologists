{
  "hash": "111024860f9ac37c2856c5161446dd03",
  "result": {
    "markdown": "---\ntitle: \"General Linear Model (GLM): Gaussian GLM\"\ndescription: |\n  A Gentle Introduction\nauthor:\n  - name: Guy F. Sutton\n    url: https://twitter.com/stats_ecology\ndate: 08-04-2021\ncategories:\n  - R\n  - tidyverse\n  - GLM\n  - ggplot2\n  - Model diagnostics\n  - DHARMa\n  - Hypothesis testing\nbibliography: biblio.bib\n---\n\n\n\n\n# General linear models (GLM's)\n\n### Background\n\nMany scared ecologists worry about which statistical test to use to analyse their hard-earned data. This is natural. Typically, some form of linear model will be used to analyse the data, whereby the relationship between a continuous response variable (`y`) is modelled with respect to one or more explanatory variables (`x1`, `x2`, ...). A general linear model (GLM) is an umbrella term for a linear model for data (residuals) that follow a normal or Gaussian distribution (more on this later). Basically, the GLM encompasses those pesky analyses you were likely taught during undergraduate statistics courses.\n\n-   A GLM where our `x` is numeric is analogous to a `linear regression`\n-   A GLM where our `x` is categorical is analogous to a `analysis of variance (ANOVA)`\n\nToday, we are going to work through a simple example of a Gaussian General Linear Model (GLM) with a single categorical `x` variable (i.e. `ANOVA`) using `R`.\n\n### The data\n\nLet's consider a study where we measure the body mass of 30 mussels (`body_mass`) from two field sites (`site`). Here, we have a single categorical predictor variable (`site`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate data to correlate X and Y amongst groups \nset.seed(2021)             \ndata1 <- data.frame(y = rnorm(n = 30, mean = 20, sd = 10),\n                    x = rep(LETTERS[1], each = 30))\ndata2 <- data.frame(y = rnorm(n = 30, mean = 35, sd = 10),\n                    x = rep(LETTERS[2], each = 30))\ndata <- dplyr::bind_rows(data1, data2) %>%\n  dplyr::rename(body_mass = y,\n                site = x)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::glimpse(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 60\nColumns: 2\n$ body_mass <dbl> 18.7754002, 25.5245663, 23.4864950, 23.5963224, 28.9805369, …\n$ site      <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", …\n```\n:::\n:::\n\n\n### Study questions\n\nWe want to evaluate whether the mass of the mussels we collected differs between the two field sites.\n\n**H~0~**: Mussel body mass is not statistically different between the two sites.\n\n**H~1~**: Mussel body mass is statistically different between the two sites.\n\n# Exploratory data analysis\n\nThe first step in our statistical analysis should familiarising ourselves with the data. To do this, you should be performing exploratory data analysis (EDA).\n\n### (i) Check the data corresponds to the experimental design\n\nThe first thing I usually do is check that the number of replicates per treatment is in line with the experimental design. In other words, we sampled 30 mussels per site, so let's just check that each site has 30 mussel body mass measurements.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Start with the data frame\ndata %>%\n  # Calculate the number of replicates per 'site' \n  dplyr::count(site)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  site  n\n1    A 30\n2    B 30\n```\n:::\n:::\n\n\nAs expected, there are 30 rows of data per site. Good start!\n\n### (ii) Visualise the data\n\nThe next step is to plot your data. You should be noting aspects such as:\n\n-   Is there a visual difference in means or the distributions of values in the different groups?\n-   Is there more variation in one group vs another group?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Start with the data frame\ndata %>% \n  ggplot(data = ., aes(x = site,\n                       y = body_mass)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](gaussian-general-linear-model-glm_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIn this case, it looks like the median body mass (indicated by the bold black line) of mussels collected at site A is lower than than at site B). The variance (i.e. spread of body mass values along the y-axis) appears to be relatively similar between the two sites.\n\n# Fitting the model\n\nFitting a GLM is relatively simple in `R`. All we need to do is tell it what is our response variable (the response variable is the measurement we are interested in). Here, the response variable is (`body_mass`). We then specify our predictor variables to the right-hand side of this weird \\~ (tilde) symbol. Our predictor variables are things we have recorded that we believe could be affecting the response variable. Here, our predictor variable was `site`. We need to tell `R` where these data are stored (`data`), and that we want a gaussian GLM (`family = gaussian()`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1 <- glm(body_mass ~ site, \n            data = data,\n            family = gaussian(link = \"identity\"))\n```\n:::\n\n\n# Evaluating model fit\n\nBefore we look at the results from our model, we must first check whether the GLM that we fit was an appropriate choice for our data. We do that by looking at model diagnostics. Model diagnostics rely heavily on calculating and visualising *residuals*. For example, let's assume we had fit a model looking at whether body length is a predictor of body mass below. The residuals are the filled black circles, indicating the deviation between our observed data value and its expected value under the given model (indicating by the unfilled circle). Simply, residuals are the observed data value minus its expected value from a model. GLM's make assumptions about the distribution of the residuals which we are going to unpack below.\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](gaussian-general-linear-model-glm_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nIn my opinion, the easiest and most informative way perform model diagnostics check in `R` is using the amazing package [`DHARMa`](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html). Below, we are going to plot two different graphs to evaluate whether our choice of model was okay.\n\nBefore we make any plots, we have to get `DHARMa` to produce residuals for us to use in our plots. We will feed these residuals into the different plotting functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulated_resids <- DHARMa::simulateResiduals(fittedModel = mod1, \n                                              plot = F)\n```\n:::\n\n\n### (i) Plot #1: QQPlot\n\nThe QQ plot tells us whether our data conforms to the distribution we specified in the `family` argument in the GLM call above (remember: we said `family = gaussian`). If our GLM is a good fit to the data, the white triangles will fall approximately on the red 1:1 line and the KS test P-value will be greater than 0.05. The Kolmorogorov-Smirnoff test (KS test) is a formal statistical test to evaluate whether our data follow the distribution we specified in the `family` argument in the GLM call above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDHARMa::plotQQunif(simulated_resids)\n```\n\n::: {.cell-output-display}\n![](gaussian-general-linear-model-glm_files/figure-html/glm_gaussian_single_categorical_qqplot-1.png){width=672}\n:::\n:::\n\n\nHere, we can see two important things. Firstly, the white triangles fall approximately along the red 1:1 line, indicating that our residuals (the white triangles) approximate the data distribution we specified in `family = ...`. Secondly, the Kolmorogorov-Smirnoff test (KS test) provides further support that the residuals from our model were not significantly different from the the data distribution we specified in `family = ...`. Taken together, the QQplot shows us that our residuals are approximately normally distributed. Great!\n\n### (ii) Plot #2: Residuals vs Predicted Plot\n\nThis plots allows us to evaluate whether our data demonstrates heteroscedasticity. This is just a fancy way to say that the variance in the data is systematically dependent on some variable in the model. If you remember back to undergraduate statistics courses, linear models typically assume that the data displays equal variances across groups or numeric variables. When our predictor variables are categorical, such as in the current model (remember `site` was our predictor variable with two levels, `siteA` and `siteB`), this plot will show boxplots with each level (e.g. each site) getting its own boxplot.\n\nIf our GLM was a good fit, we would like the boxplots to be centered between y = 0.25 to y = 0.75, with the bold black line falling approximately on the y = 0.5 line. `DHARMa` has recently introduced a nice function which automatically produces a formal statistical test for within-group uniformity and between-group homogeneity of variances. Ultimately, we want both of these tests to return `n.s.` meaning a non-significant result.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDHARMa::plotResiduals(simulated_resids)\n```\n\n::: {.cell-output-display}\n![](gaussian-general-linear-model-glm_files/figure-html/glm_gaussian_single_categorical_resids-1.png){width=672}\n:::\n:::\n\n\nThe plot shows us that there aren't major concerns over unequal variances. While we would like to see the left-hand boxplox grey-shaded area range from y = 0.25 to 0.75 (it ranges from y = 0.33ish to 0.80), both the test for uniformity and unequal variances test were `n.s.`. In later posts, we will unpack model diagnostics in much greater detail. Stay tuned.\n\n# Statistical inference\n\nNow to the bit of the analysis that most ecologists are most interested in (at least to appease their reviewers: assessing statistical significance and calculating p-values). Here, we perform statistical inference, which basically means we are going to evaluate \"which \\[model\\] coefficients are non-zero beyond a reasonable doubt, implying meaningful associations between covariates and the response?\" [@tredennick2021practical].\n\nTo do this, we will use a Likelihood Ratio Test (LRT). When we only have 1 predictor variable (here: `site`), we can calculate p-values using type I sum-of-squares (SOS). SOS's are just different ways that we ask `R` to calculate p-values.\n\n**PLEASE DO NOT USE SUMMARY() - THIS WILL PRODUCE THE WRONG P-VALUES WHEN YOU HAVE MORE THAN 1 PREDICTOR VARIABLE**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform LRT with type I sum-of-squares \nanova(mod1,\n      test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel: gaussian, link: identity\n\nResponse: body_mass\n\nTerms added sequentially (first to last)\n\n     Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \nNULL                    59     8481.1              \nsite  1     1498        58     6983.1 0.0004198 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nSo, the LRT tells us that mussel `body_mass` was statistically significantly different between sites ($\\chi$^2^ = 1498, d.f. = 1, *P* \\< 0.001).\n\n# Make a figure\n\nNow we are going to make a figure to summarise our findings and that you can include in your thesis or paper.\n\n\n::: {.cell preview='true'}\n\n```{.r .cell-code}\n# Calculate mean +- standard error\ndata %>%\n  ggplot(data = ., aes(x = site,\n                       y = body_mass,\n                       fill = site)) +\n  geom_boxplot() +\n  # Fill the boxes by site\n  scale_fill_grey(start = 0.6) +\n  # Add significance letters\n  scale_x_discrete(\"Site \",\n                   labels = c(\"A\", \"B\")) +\n  annotate(\"text\", x = 1, y = 40, label = \"a\") +\n  annotate(\"text\", x = 2, y = 60, label = \"b\") +\n  # Change axis labels\n  labs(y = \"Mussel body mass (mg)\")\n```\n\n::: {.cell-output-display}\n![](gaussian-general-linear-model-glm_files/figure-html/glm_gaussian_single_categorical_plot-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n# Conclusions\n\nThere we go!!! You are now equipped to run your own GLM. Please let me know if there are any improvements or what topics you would like me to cover going forward.\n",
    "supporting": [
      "gaussian-general-linear-model-glm_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}